# Embedding
**keyword**: 워드 임베딩, 원-핫 인코딩, BOW, DTM, TF-IDF, Word2Vec, FastText, GLOVE

1. Embedding이란?
  - Emdedding은 고차원의 정보를 저차원으로 변환하면서 필요한 정보를 보존하는 과정을 말한다.
  - 컴퓨터는 word 그 자체를 이해하지 못하므로 숫자로 변환시켜주어야 한다.
  - word emdedding은 각 단어를 인공신경망 학습을 통해 벡터화하는 방법 및 일련의 과정을 말한다.
  - "언어의 벡터화"
    - _**Why?**_  
      벡터는 숫자 하나의 크기 만으로 표현하지 않는다. 속도나 물리적인 힘처럼 '방향' 역시 가지고 있다.  
      벡터의 이러한 성질을 통해 각 단어들 간의 거리를 계산할 수 있다.
      유사한 단어일 수록 거리가 가까워진다.
      
2. Word Embedding  
   - "단어를 밀집 공간으로 표현하는 것"
   - 
